# 実行パターンとベストプラクティス

このドキュメントは、分解された中間目標を効果的に実行するためのパターンとベストプラクティスを説明します。

## 実行モード

### 1. 完全自動実行モード

**特徴**:
- すべてのステップを自動的に連続実行
- 人間の介入なしで進行
- 進捗は自動記録される

**適用場面**:
- 定型的なタスク
- 完全に自動化可能なワークフロー
- バッチ処理的な作業

**コマンド例**:
```bash
python execute_steps.py decomposed_goal.json
```

### 2. インタラクティブモード

**特徴**:
- 各ステップで人間の確認・入力を求める
- 実行結果のメモを記録できる
- ステップのスキップや再試行が可能

**適用場面**:
- 判断が必要なタスク
- 学習や探索的な作業
- 品質確認が重要な作業

**コマンド例**:
```bash
python execute_steps.py -i decomposed_goal.json
```

### 3. ハイブリッドモード

**特徴**:
- 自動実行と人間の確認を組み合わせる
- 重要なステップのみ確認を求める

**実装方法**:
- 特定のステップに「要確認」フラグを設定
- 自動実行中に確認ポイントで一時停止

## エラーハンドリング戦略

### 1. 即座に停止

**動作**:
- エラーが発生したらすぐに実行を停止
- エラーログを記録
- 手動で問題を解決してから再開

**適用場面**:
- クリティカルなエラーが許容できない場合
- 後続のステップがエラー発生ステップに強く依存している場合

### 2. スキップして続行

**動作**:
- エラーが発生したステップをスキップ
- 残りのステップを実行
- スキップされたステップは後で再試行可能

**適用場面**:
- 並列実行可能な独立したステップが多い場合
- エラーの影響範囲が限定的な場合

### 3. リトライ戦略

**動作**:
- エラー発生時に自動的に再試行
- 再試行回数と間隔を設定可能
- 再試行上限に達したら停止またはスキップ

**設定例**:
```json
{
  "retry": {
    "max_attempts": 3,
    "delay_seconds": 5,
    "backoff_multiplier": 2
  }
}
```

**適用場面**:
- ネットワークエラーなど一時的な問題が想定される場合
- 外部APIやサービスへの依存がある場合

### 4. フォールバック実行

**動作**:
- 主要な方法が失敗した場合、代替方法を試行
- 複数の代替手段を定義可能

**例**:
```
ステップ: データベース接続
  方法1: PostgreSQL接続
    ↓ 失敗
  方法2: SQLite フォールバック
```

## 進捗管理パターン

### 1. リアルタイム進捗記録

**特徴**:
- 各ステップの開始・完了時に即座に記録
- 異常終了時にも進捗が保存される

**実装**:
```python
# ステップ開始時
update_progress(step, status="in_progress")
save_progress()

# 処理実行
execute_step_logic()

# ステップ完了時
update_progress(step, status="completed")
save_progress()
```

### 2. チェックポイント方式

**特徴**:
- 特定の重要なポイントでのみ進捗を保存
- I/Oオーバーヘッドを削減

**適用場面**:
- 高速実行が求められる場合
- ステップ数が非常に多い場合

### 3. ロールバック可能な進捗管理

**特徴**:
- 各ステップの実行前に状態を保存
- エラー時に前の状態にロールバック可能

**実装例**:
```json
{
  "checkpoints": [
    {
      "step": 3,
      "timestamp": "2025-01-15T10:30:00",
      "state_snapshot": {...}
    }
  ]
}
```

## 並列実行パターン

### 1. 完全並列実行

**条件**:
- 依存関係のないステップを同時実行
- システムリソースが十分にある

**例**:
```
ステップ2: フロントエンド実装  }
ステップ3: バックエンド実装    } 並列実行
ステップ4: データベース設計    }
```

### 2. パイプライン実行

**条件**:
- 前のステップの一部が完了したら次を開始
- ストリーミング処理的なワークフロー

**例**:
```
ステップ1: データ収集 ──→ ステップ2: データ処理 ──→ ステップ3: 可視化
         (継続中)          (開始可能)
```

### 3. バッチ並列実行

**条件**:
- 同じ処理を複数のデータに適用
- MapReduceパターン

**例**:
```
ステップ5: 100個のファイルを処理
  → バッチ1: ファイル1-25  }
  → バッチ2: ファイル26-50 } 並列実行
  → バッチ3: ファイル51-75 }
  → バッチ4: ファイル76-100}
```

## 実行最適化

### 1. 依存関係解析による最適化

**手法**:
- ステップの依存関係グラフを作成
- クリティカルパスを特定
- 並列実行可能なステップを自動検出

**効果**:
- 実行時間の短縮
- リソースの効率的な利用

### 2. 事前検証

**手法**:
- 実行前にすべての前提条件をチェック
- 必要なリソースの可用性を確認
- 依存関係の整合性を検証

**チェック項目**:
- 必要なファイル・ディレクトリの存在
- 環境変数の設定
- 外部サービスの疎通確認
- ディスク容量・メモリの十分性

### 3. ドライランモード

**特徴**:
- 実際の変更を行わずに実行手順を確認
- 実行時間の見積もり
- 潜在的な問題の早期発見

**実装例**:
```bash
python execute_steps.py --dry-run decomposed_goal.json
```

## モニタリングとロギング

### 1. 構造化ログ

**形式**:
```json
{
  "timestamp": "2025-01-15T10:30:45",
  "level": "INFO",
  "step": 3,
  "message": "API接続成功",
  "details": {
    "endpoint": "https://api.example.com",
    "response_time_ms": 245
  }
}
```

### 2. 進捗可視化

**方法**:
- プログレスバー
- ステップ完了率
- 推定残り時間
- リアルタイムダッシュボード

### 3. アラート設定

**トリガー**:
- ステップが想定時間を超過
- エラー発生
- リソース使用率が閾値を超過

## 実行後の処理

### 1. 結果の検証

**チェック項目**:
- すべての目標が達成されたか
- 成果物の品質は十分か
- 副作用や問題は発生していないか

### 2. クリーンアップ

**対象**:
- 一時ファイルの削除
- 不要なリソースの解放
- ログファイルのローテーション

### 3. レポート生成

**含めるべき情報**:
- 実行サマリー
- 各ステップの所要時間
- 発生したエラーと対処方法
- 教訓と改善提案

## ベストプラクティス

### DO（推奨）

- ✅ 各ステップの開始前に前提条件を確認する
- ✅ 進捗を頻繁に保存する
- ✅ エラーメッセージを詳細に記録する
- ✅ ステップ間で状態を明示的に受け渡す
- ✅ 実行時間を測定して記録する
- ✅ ロールバック手段を用意する
- ✅ 冪等性を確保する（同じステップを複数回実行しても安全）

### DON'T（非推奨）

- ❌ エラーを無視して続行する
- ❌ グローバル状態に依存する
- ❌ ステップ間で暗黙的な依存関係を作る
- ❌ 進捗保存を怠る
- ❌ ログを残さない
- ❌ 実行時間の見積もりを無視する
- ❌ すべてのステップを直列実行する（並列化の機会を逃す）

## トラブルシューティング

### 問題: ステップが完了しない

**原因と対処**:
- 無限ループ → タイムアウト設定を追加
- 外部依存の遅延 → リトライ戦略を設定
- リソース不足 → リソース監視を追加

### 問題: 進捗が保存されない

**原因と対処**:
- ファイルアクセス権限 → パーミッション確認
- ディスク容量不足 → ディスク空き容量確認
- プロセス異常終了 → try-finally で保存を保証

### 問題: 依存関係エラー

**原因と対処**:
- 循環依存 → 依存関係グラフを再設計
- 依存順序の誤り → トポロジカルソートで実行順序を決定
- 並列実行での競合 → ロックやセマフォで同期制御
